{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rodotasso/preguntas_collab/blob/main/Copia_de_nov_2024_Audio_a_texto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Esto instala los paquetes iniciales, asi funciona todo lo dem√°s."
      ],
      "metadata": {
        "id": "qtd69FxDoo6I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf9vEBzXBmeS",
        "outputId": "fc5e7a34-6ab1-4180-b7f1-9eb480463cb9",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer) (8.3.0)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
            "Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m121.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-4.0.0 rapidfuzz-3.14.3\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.10.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,532 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,465 kB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,149 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,864 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,290 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,988 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,829 kB]\n",
            "Fetched 31.1 MB in 4s (7,162 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "41 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "!pip install jiwer\n",
        "!pip install librosa\n",
        "!pip install pydub\n",
        "!pip install -U ffmpeg-python\n",
        "!pip install ffmpeg-python -q\n",
        "!apt update && apt install -y ffmpeg #Solo en caso de que no se instale la version necesaria.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Esto linkea con Google Drive en caso de utilizar archivos desde alla"
      ],
      "metadata": {
        "id": "_OYG9WhF9DS7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llrLgGSnCAzg",
        "outputId": "a5c2c6ab-36a9-4e18-b8ff-3f2d4b920e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu8ub2EN1-Yk",
        "outputId": "d9ad33ff-fc91-4509-9890-1cc409967698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9_I0W3tqTjr"
      },
      "source": [
        "## üéôÔ∏è **Transcribir**, Lee la mayoria de formatos de audio gracias a ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a0ZYg2EufpCY",
        "outputId": "57872330-f511-4e18-85f1-36cc7d88048e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El archivo de audio es: /content/drive/MyDrive/transcipciones/Bio 27-06(2).m4a\n",
            "La transcripci√≥n se guardar√° en: /content/drive/MyDrive/transcipciones/Transcipciones hechas/Clases sin formato /Bio 27-06(2).txt\n",
            "Cargando modelo Whisper (medium)...\n",
            "Modelo cargado.\n",
            "Intentando transcribir el archivo...\n",
            "\n",
            "-- TRANSCRIPCI√ìN OBTENIDA --\n",
            "\n",
            " Por cada caso hay un control. Pero uno podr√≠a pensar que hay una ganancia si por cada caso elijo dos controles, o tres controles, o cuatro controles. Entonces lo que uno podr√≠a evaluar o cuantificar, ya que tenemos ah√≠ la sintaxis para estudio de casos y controles, en STATA variando la cantidad de cuantos casos y controles, haciendo el ejercicio y tratar de reproducir qu√© pasar√≠a con la potencia si uno considera en vez de un caso un control por cada caso, sino cuatro controles por cada caso. Sin embargo, uno, como les digo, haciendo este ejercicio que corresponder√≠a a simulaciones, uno puede encontrarse aqu√≠ con esta figura que nos muestra en el eje horizontal la raz√≥n control caso. Por ejemplo, ah√≠ el valor 1 significa que hay un control por cada caso, uno a uno, aqu√≠ el 2 y de nota que hay dos controles por cada caso. Y en el eje y tenemos la potencia del estudio. Y claro, partiendo una potencia del 90%, c√≥mo cambia este valor de potencia si uno va variando la cantidad de controles por cada caso. Y lo que observamos es que en realidad a partir ya de tres controles por cada caso, ya no mejora tanto la potencia. Ya tenemos aqu√≠ cercano a un casi 98%, pero eso no mejora tanto los t√©rminos de esta medida que es la potencia. Por lo tanto, esto nos ayuda a entender tambi√©n el concepto cuando calculamos tama√±o de muestra desde el punto de vista de la potencia. En algunos casos, aumentar o duplicar o triplicar ese tama√±o de muestra no hace que mejore la potencia en el estudio. Lo que va a hacer en el fondo es que gastes m√°s recursos, m√°s tiempo en ir a contactar a los participantes. Entonces, aqu√≠ hay una situaci√≥n bastante interesante para al finalizar el concepto que tampoco cuando uno calcula tama√±o de muestra, lo est√° haciendo solamente para tener a veces el concepto de muestra representativa. Mientras m√°s grande la muestra es m√°s representativa. Tambi√©n aqu√≠ la evidencia no puede decir, bueno, pero si uno aumenta la cantidad de controles por cada caso, desde el punto de vista de esta medida que es la potencia del estudio, no puede ser que la potencia de la muestra sea m√°s grande. Desde el punto de vista de esta medida que es la potencia del estudio, no va a cambiar tanto, pero s√≠ obviamente va a cambiar el presupuesto del estudio. Entonces es interesante eso, porque a veces uno cree que el tama√±o de la muestra tiene que ser bastante grande para que en el fondo haya una buena potencia, pero va a depender mucho del tipo de dise√±o en el fondo que uno est√° considerando. Entonces, este es un ejercicio que ustedes lo pueden realizar con la funci√≥n ah√≠ que ten√≠amos Power en esta tab, y ir variando la relaci√≥n control-casos. ¬øQu√© pasa si elijo en vez de un caso por cada control, perd√≥n, un control por cada caso, elijo dos controles o tres controles por cada caso? ¬øC√≥mo va cambiando la potencia? Eso se podr√≠a hacer ah√≠ con la sintaxis que hemos visto con el STATA. Por otro lado, la justificaci√≥n de por qu√© muchos investigadores y investigadoras se deciden hacer estudios de casi controles, y como estudios de cohorte quedan en el fondo para grandes muestras. Entonces ah√≠ tenemos los tama√±os de muestra que vamos a encontrar. Si hacemos el estudio bas√°ndonos en uno de cohorte o en lo que es caso de control, pero obviamente esto es netamente operativo, ¬øqu√© pasa con el tama√±o de muestra si elijo el dise√±o casi control o si elijo que esa justificaci√≥n no es lo suficientemente v√°lida en tama√±o de muestra? Pero s√≠, es importante, porque tiene que haber m√°s TCD de la hip√≥tesis de trabajo, el tipo de pregunta que te est√°s planteando, que sea m√°s adecuado hacerlo como corte y no como caso de control. Pero veamos esta parte m√°s operativa, ¬øqu√© pasa ah√≠ con el tama√±o m√°s? Los tama√±os de muestra que uno calcula en cohorte dependen de la variable de respuesta, la tasa de la variable de respuesta, y no de la prevalencia de la exposici√≥n en el fondo. En cambio, los estudios de casi controles de tama√±o de muestra dependen de la prevalencia de la exposici√≥n y no tanto de la tasa de la respuesta. Entonces, cuando tenemos tasa de respuesta peque√±a en comparaci√≥n a la prevalencia de exposici√≥n, los estudios de corte requieren un grande tama√±o muestra, para alcanzar la misma potencia que tendr√≠a un estudio de caso y control. Y si uno se fija aqu√≠ en esta tablita, por ejemplo, un estudio que queremos relacionar tabaco con enfermedad coronaria, y tenemos all√≠ que la tasa de incidencia es de 0,09 eventos por persona en riesgo que no estuviera en un coche, y la prevalencia del factor de riesgo es de 0,3 o un 30%. Entonces, con esto antecedente, queremos estimar un riesgo relativo dado, suponiendo una potencia del 90% y un nivel de significaci√≥n del 5%. Y esto mirando desde un dise√±o de corte o mir√°ndolo en un dise√±o de caso y control. Entonces, aqu√≠ en esta tabla interesante, porque claro, uno para este tipo de dise√±o va a tener que plantearse, ¬øcu√°l va a ser el riesgo relativo cuando voy a calcular el tama√±o muestra? Necesito esta medida, o sea, ¬øcon qu√© riesgo relativo voy a calcular el tama√±o muestra? Aqu√≠ vemos entonces los distintos riesgos relativos, 1,1, 1,3, 1,5, 2,3. Y dentro aqu√≠ vemos cada columna el tama√±o de la muestra relirida si lo miramos como un dise√±o de corte o como un dise√±o de caso y control. Entonces, si nos planteamos por ejemplo un riesgo relativo, nos toma 5, en estudio corte vamos a tener que estudiar 2070, participar de la reuni√≥n de 2017. En cambio, en el estudio de gas y control ser√≠a la mitad, 1532. Entonces, en el fondo, esa es una de las razones, porque en general uno ve muchos estudios en este bajote de dise√±o de gas y control. Porque en el fondo, el N para un mismo nivel de potencia y nivel de significaci√≥n requiere la mitad de participantes de lo que ser√≠a el dise√±o del cohorte. Y esas son las razones porque uno ve mucho la revista en salud p√∫blica, dentro de los estudios observacionales la mayor√≠a son estudios basados en caso y control. Obviamente con toda la cejo que puede tener los estudios de caso y control, las deficiencias que podr√≠a tener llegar a mirarlo como estudio de caso y control. Pero va a determinar mucho, como se dice all√≠, lo que es la prevalencia del evento, lo que son la cantidad, la tasa de incidencia por ejemplo, la prevalencia factor de riesgo. Es cuando uno tiene que tomar la decisi√≥n, bueno, lo miro como un estudio corte o lo miro como un estudio caso y control. En general los estudios cortes que uno va a mirar, claro, uno dice, ¬°uy! tama√±o de macho bastante grande, cierto. Porque en el fondo para poder evaluar esas diferencias, para poder medir estos riesgos, se necesita reclutar una gran cantidad de participantes y eso la √∫nica manera que uno puede abordarlo es haciendo estudios multis√©tricos, haciendo estudios con participantes de otros pa√≠ses por ejemplo. O a lo mejor lo que uno ve por ejemplo es estudios que se hacen en China, en la India, en pa√≠ses super grandes porque en el fondo tienen una gran cantidad de participantes, pueden llegar a cubrir una gran cantidad de participantes, pero en pa√≠ses m√°s chiquitos como el nuestro digamos es dif√≠cil. Tomar√≠a mucho tiempo reclutar tantas personas y ah√≠ entonces son unas de las razones por las cuales digamos los estudios de corte son de tama√±o m√°s peque√±o o generalmente son estudios en los cuales participan pa√≠ses digamos de la regi√≥n ya sea sur o de Latinoam√©rica que est√°n trabajando. Es una de las razones que no es que uno pierda potencia o nivel de significaci√≥n sino que en el fondo desde el punto de vista del estudio corte necesito mucho m√°s participantes. Y esa es desde el fondo la precauci√≥n que uno se debe plantear cuando est√° evaluando en t√©rminos de cu√°ntos participantes van a participar y todas estas condiciones o estos elementos, digamos la potencia, el nivel de significaci√≥n, etc. Bueno hemos visto una revisi√≥n bastante breve de los elementos para el c√°lculo de tama√±o muestra, pero en el fondo cuando uno ya estaba trabajando el dise√±o m√°s grande claro este texto es bastante interesante, el √∫ltimo ah√≠ de Levy y Levy Show, que ya les debe sonar el nombre este Levy Show por todos los trabajos o mancrete digamos lo que se hace en salud p√∫blica en lo que se llama el test de Levy Show y cosas as√≠ de bibliog√≠a. Pero es bastante interesante este texto porque en el fondo da m√°s herramientas no solamente como c√°lculo tama√±o muestra sino como debo elegir a los participantes qu√© tipo de dise√±o va a ser un dise√±o estratificado, un dise√±o por conglomerado, etc√©tera, etc√©tera, que hay varios tipos de ellos. Y bueno aqu√≠ tambi√©n este manual bastante interesante porque es como el manual por tapagas, la ayuda m√°s directa que nos puede consultar de la OMS, el tama√±o muestra el estudio salud, el manual pr√°ctico, que tambi√©n lo recomiendo ah√≠ para en el fondo cuando uno va a preparar su estudio, su trabajo, esas consideraciones que tiene que tener. Porque es algo bastante aplicado y sabemos que bueno hay muchos estudios que hace la OMS tambi√©n en pa√≠ses subdesarrollados donde llegar a reclutar, llegar a tomar, a considerar participantes con muestras muy grandes a lo mejor. Hay problemas de acceso, hay problemas digamos de participaci√≥n, entonces es interesante all√≠ que los que escribieron, los que participaron en este manual tambi√©n muestran ah√≠ algunos ejemplos, algunas situaciones de pa√≠ses digamos en los cuales es dif√≠cil tomar estas muestras. Y bueno ah√≠ el primer libro, el Woodward, es un poco m√°s ya aplicado obviamente en epidemiolog√≠a, lo que es dise√±o, estudio y el an√°lisis de los datos. Y es un texto bastante complejo, es algo que dir√≠amos para no solamente el tama√±o muestra sino que para varios aspectos de lo que es el an√°lisis de estos tipos de dise√±o en la bibliolog√≠a. No s√©, alguna pregunta, alguna duda? Yo que hab√≠a mencionado que los estudios de corte dependen entonces de la variabilidad de la respuesta y no de la prevalencia de exposici√≥n versus los pasos de control que dependen de la prevalencia y ah√≠ ellos no depender√≠an de la variabilidad de la respuesta? Claro, en el fondo cuando uno est√° pensando en los estudios de cohortes digamos podr√≠amos decir con qu√© porcentaje tenemos la respuesta medida, digamos que ser√≠a esa tasa de respuesta. Y cuando uno est√° pensando en los de cohortes principalmente el caso y controles, perd√≥n, principalmente uno se fija m√°s bien esa exposici√≥n porque claro por el tipo de dise√±o uno tiene que, bueno, ojal√° encontrar algunos individuos que hayan estado expuestos digamos a esta condici√≥n porque si no, no puedo ah√≠ evaluar esa diferencia entre los casos y los controles si no tengo suficientes personas que estuvieron expuestas. No as√≠ los de dise√±o digamos de cohortes que no me interesa tanto la prevalencia de exposici√≥n sino como va ocurriendo el evento de inter√©s digamos y el fallecimiento por ejemplo en ese seguimiento bueno me interesa m√°s mirar en eso que en la cantidad de personas que estuvieron expuestas o no expuestas. Claro, eso es lo que mencionaba. Bueno voy a mostrar aqu√≠ la gu√≠a que tengo que dar a la mano aqu√≠. Claro, es el documento que les mencionaba, que uno puede julgar y est√° disponible digamos ah√≠, que son checklists como dice el t√≠tulo, que consideraciones hay que tener en cuenta que no es una que son checklists como dice el t√≠tulo, que consideraciones hay que tener al momento de informar, de comunicar los resultados del estudio observacional. Y como les mencionaba esto tambi√©n en alguna revista te lo exigen, te dicen bueno por favor mencione que aspecto dentro de su estudio se adhiere a la gu√≠a de este estudio observacional. Entonces ah√≠ si te fijas bueno te ayuda tambi√©n obviamente para redactar tu protocolo, tu AFE, tu tesis, el t√≠tulo, la introducci√≥n, los objetivos, si habian ya preparado su proyecto digamos se van a enterar que hay una gu√≠a por ejemplo ah√≠ el seminario tesis que se le entreg√≥, entiendo alg√∫n documento que lo que debe contener desde inicialmente el proyecto y despu√©s lo que va a hacer el trabajo de AFE. Y aqu√≠ les mencionaba justamente, por ejemplo los participantes iba a depender si un estudio corte, un estudio casi control, un estudio transversal por ejemplo. Y m√°s abajo aqu√≠ m√©todo estad√≠stico. Y en esta parte hay que tenerlo claro porque uno va a aplicar muchas pruebas estad√≠sticas y todas estas cosas pero uno tiene que declarar en la secci√≥n m√©todo. Entonces entre ellas justamente va a encontrarse... Bueno, ah√≠ tambi√©n los participantes. Bueno en general los estudios cortes, pasa que hay estos seguimientos, hay perdidos y en algunas de las publicaciones te piden hacer un diagrama de flujo tambi√©n ah√≠ como el punto C. Voy a tener un diagrama de flujo como han ido desglos√°ndose a trav√©s de todo el trabajo. S√≠, s√≠. Bueno, pero la parte del m√©todo entonces como les digo. Bueno, lo interesante de este documento es que va a ayudar a... bueno ah√≠ se llama tama√±o del estudio que en el fondo sabe que deber√≠a ser el tama√±o de la muestra que uno quiere considerar. Este deber√≠a ser la √∫ltima versi√≥n parece. Porque esto lo va cambiando cada cierto tiempo se re√∫ne este comit√© digamos de lo que son. Bueno, pero t√©nganlo en cuenta digamos si van a trabajar sobre todo en estudios cuantitativos observacionales, todo este aspecto digamos de c√≥mo ir desglosando el estudio. Y al momento de publicarlo en algunos casos tambi√©n de la revisi√≥n que hacen digamos las personas del manuscrito te preguntan a lo mejor algunos √≠tems ah√≠ que si corresponden a esta gu√≠a stroke. Bueno, tambi√©n lo sejo, potencial sejo, limitaci√≥n, eso tambi√©n tiene que ir indicado. Pregunta, dudas, algo que quieran. Bueno, se supone que en la siguiente clase tenemos la evaluaci√≥n de... No, pero espera, quer√≠a evaluar lo que es... Pues s√≠, porque ya hemos la √∫ltima control y evaluamos lo que es binomial y tal vez alguna cosa de tama√±o muestra podr√≠a ser... Ah, y tenemos una tarea que no les he entregado tampoco. La segunda tarea, que es una tarea y control. ¬øCu√°ndo nos va a tirar la prueba? S√≠, no, pues puede ser. El d√≠a de la prueba me entra en la tarea, no. No, no s√©, a ver la delegada que quiere plantear un poco. Lo que pasa es que ya comenzamos con la prueba porque pensamos que iba a ser la de comodalidad, que iba a ser juntos. Entonces nos dimos cuenta que el 11 de julio ten√≠amos la prueba de Geyer. Tenemos como 12, entonces creemos que la posibilidad de volver a la misma modalidad de que ser√° una prueba de conjunto y as√≠ tener menos c√°lidos con el igual y nos ha evaluado todo, pero al final es solamente uno. Y en t√©rminos de fecha, ¬øsera la misma fecha? No, pero una del 10 y otra del 11. Claro, en la noche del 11. Entonces, ¬øte hab√≠amos propuesto dejar la evaluaci√≥n para el viernes y tal vez jueves para ese bloque para hacer un taller como le hicimos la otra vez con la profe o con otro ambiente? S√≠. ¬øQu√© le parece? Porque nos queda Poisson y... Poisson es un poco de tama√±o de muestra en realidad. Tampoco como contenido de biostat√≠sticas ya hemos visto bastante. ¬øY lo otro que le pareci√≥ una gu√≠a como... S√≠, s√≠. No, si eso la otra vez me hab√≠a dicho que era ejercicio, no s√©. Una de ustedes me hab√≠a dicho que era una gu√≠a, ejercicio, principalmente Poisson. Pero tambi√©n la opini√≥n, ¬øt√∫ y tu est√°n todos de acuerdo? S√≠, porque pens√°bamos que para no tener como evaluaci√≥n el jueves y evaluaci√≥n el viernes, porque por ejemplo el tercer d√≠a tuvimos la fecha de la ma√±ana y despu√©s salimos tempranos. Como que si vamos a hacer eso los dos d√≠as preferir√≠amos tenerla el viernes y despu√©s poder hacer verduras. Claro, s√≠. ¬øAqu√≠ est√° el jugador? S√≠, no, no. Hablamos de que el jueves est√° s√∫per dispuesta a hacer algo como... S√≠. Normal no le quer√≠amos a la casa conversar con usted. S√≠, no, pero ustedes tambi√©n que tienen que estar de acuerdo todos porque... Alguien est√° de acuerdo. No, no es que haces una votaci√≥n y nada, pero... ¬øMe vale seguir? S√≠, bueno, a mi parte si quieren seguir en esta modalidad de solo control donde hay dos bloques que se eval√∫an, es un problema. Y quedar√≠a para el once, eso es cierto, s√≠. Claro, s√≠. Entonces el d√≠a once hacemos el control conjunto con Epi. Claro. Y s√≠, la misma modalidad que ten√≠amos. En este caso, bueno, creo que va a ser m√°s de Epi las preguntas que de... de Vieta Iti o que no hay mucho. De Mario, por as√≠ decirlo. ¬øSolo Juanso? Entra todo. Entra todo. Es que... Si, pero el pecado se que eso no va a quedar. No, pero s√≠, tambi√©n hay el trabajo final que tambi√©n ah√≠ se eval√∫a todo, s√≠, eso es lo que... Hay esa parte, digamos que... No, en mi caso, pues son y algunas cosas de tama√±o muestra, seguramente. Pero m√°s bien de... Digamos... Preguntas de verdadero y falso alternativas sobre... Estadia positiva, por as√≠ decirlo. Ya. Pero... Pero, claro, como es menos materia, seguramente la profe Vero va a introducir m√°s cosas. Ya. S√≠, ¬øno? Me parece, entonces, que vamos a... A ver, vamos a ver. A ver, vamos a ver. A ver, vamos a ver. A ver, vamos a ver. A ver, vamos a ver. A ver, vamos a ver. A ver, vamos a ver. A ver, vamos a ver. A ver, vamos a ver. S√≠, ¬øno? Me parece, entonces, que vamos en un solo control el d√≠a viernes, conjunto, y enviarle el ejercicio, alg√∫n ejercicio de poas√≥n con algunas cosas, seguramente, muestra. No estoy segura si ese viernes vamos a trabajar abajo mejor en la sala de computaci√≥n, ah√≠, haciendo la probad√≠a. Ya. No es que hay que usar el estatano, pero... Porque va a estar disponible. Ocupar esta sala parece ser viernes once, as√≠ que... Tenemos un firmar. Vamos a cambiar de sala. ¬øNo podemos usar la sala de...? La 3 once. La 3 once o la 3 tres. Porque ah√≠ no va a haber choque de cortes, de conf√≠cter. As√≠ que, ¬øpodr√≠amos estar desocupadas? No. Ya. Ok. Bueno. Ya. Quedamos, entonces, para el d√≠a once en un control √∫nico. Les tengo que enviar... Y bueno, y tengo que preparar esta tarea dos, que es grupar tambi√©n, al igual que el... No s√© si quieren trabajar los mismos grupos, los mismos integrantes de cada grupo, digamos. Por tanto, eran cinco grupos, entiendo. Y env√≠o ah√≠ mi trabajo de esa segunda tarea. Claro, con m√°s tiempo, obviamente. Y... No s√©, m√°s dudas, consultas... ¬øTanto de acuerdo, entonces? En hacer el viernes once la prueba de comienzo. Ya. Ya me parece. ¬øPero c√≥mo no fue la tarea uno? ¬øAh? ¬øC√≥mo no fue la tarea uno? ¬øSe subieron las notas? No. No. ¬øD√≥nde se sub√≠an? ¬øEn el sistema de notas o en el sistema de... ¬øEst√° en la plataforma? En notas... La tarea ah√≠, la que us√≥ la... ¬øAh? Perd√≥n. Vamos, perd√≥n. ¬øDeber√≠a estar? ¬øDeber√≠a estar? S√≠, eso hace tiempo ya que... Lo que pasa es que... Se lo envi√© a la secretaria. ¬øA los lugares? ¬°Oh! ¬°Oh! No, pero ustedes ven el seguimiento ah√≠ de su rendimiento, como me imagino. S√≠. ¬°Qu√© doloroso! ¬øDeber√≠a estar? ¬°Qu√© doloroso! ¬°Qu√© doloroso! ¬øDeber√≠a estar en calificaci√≥n? No est√°. ¬øTe ha dicho que no deber√≠a poder? Ya. No, pero apareci√≥ en la prueba. ¬øNo est√°? Solo la prueba apareci√≥. Pero no hab√≠a dicho que no hab√≠a ido a todos bien y que no hab√≠a ido a todos bien. ¬øNo? ¬øNo? ¬øNo? ¬øNo? ¬øNo? ¬øNo? ¬øNo? ¬øNo? ¬øNo? ¬øNo? ¬øNo? ¬øNo? ¬øNo? ¬øNo? ¬øNo? ¬øNo? ¬øNo? S√≠. S√≠. Estaba la notaÏÉù. Qu√© doloroso. ¬øNo est√°? ¬øNo est√°? No s√≠ no est√°. Lo que pasa es que la entrega lo ha pedido por correo tambi√©n. S√≠, pero la evalu√© y todo y ya tengo ah√≠ la calificaci√≥n. S√≠. S√≠, s√≠, voy a preguntarle aqu√≠ a la Secretar√≠a si se transpapel√≥, pero est√° esa nota. ¬øNo parece? ¬øNo parece? No, pero est√°. ¬øY que te lo metieron? No, pero... ¬°Bien corto! ¬°Sin grabar, sin grabar! Bueno, quedamos hasta ac√° entonces. Si quieren seguir trabajando en lo que es el trabajo final, pueden seguir trabajando ac√° o... Deciden ah√≠ ustedes si quieren hacer otra cosa. ¬øT√∫? Eh... Para revisar la prueba. S√≠, bueno, si alguien quiere revisar la prueba tambi√©n, voy a... Voy a traerla. No, quiero que lo traiga. ¬°Juntos! ¬°Aqu√≠ est√° peleado! ¬°Buenos d√≠as! ¬°Buenos d√≠as! ¬°Pero no puedo, no puedo! ¬°Hostia! ¬°Buenos d√≠as!\n",
            "\n",
            "Guardando transcripci√≥n en /content/drive/MyDrive/transcipciones/Transcipciones hechas/Clases sin formato /Bio 27-06(2).txt...\n",
            "¬°Transcripci√≥n guardada exitosamente!\n"
          ]
        }
      ],
      "source": [
        "# --- PASO 1: Instalar Whisper (si no lo has hecho) ---\n",
        "# !pip install git+https://github.com/openai/whisper.git -q\n",
        "\n",
        "# --- PASO 2: Importar Whisper y os/pathlib ---\n",
        "import whisper\n",
        "import os\n",
        "from pathlib import Path # Pathlib es muy √∫til para manejar rutas y nombres de archivo\n",
        "\n",
        "# --- PASO 3: Especificar la RUTA de tu archivo de audio ---\n",
        "# !!! CAMBIA ESTA L√çNEA por la ruta real a tu archivo de audio !!!\n",
        "ruta_del_audio = \"/content/drive/MyDrive/transcipciones/Bio 27-06(2).m4a\" # <----------------------------------------------------- ¬°¬°¬°MODIFICA ESTA RUTA!!!, ESTE ES EL ARCHIVO A TRANSCRIBIR\n",
        "\n",
        "# --- PASO 3.5: Especificar D√ìNDE guardar el archivo .txt ---\n",
        "# Opci√≥n 1: Guardar en la misma carpeta que el audio, con el mismo nombre base + .txt\n",
        "#ruta_audio_path = Path(ruta_del_audio)\n",
        "#carpeta_salida = ruta_audio_path.parent # Obtiene la carpeta del archivo de audio\n",
        "#nombre_base_salida = ruta_audio_path.stem # Obtiene el nombre sin extensi√≥n (ej: \"425\")\n",
        "#ruta_archivo_txt = carpeta_salida / (nombre_base_salida + \".txt\") # Crea la ruta completa (ej: \".../425.txt\")\n",
        "\n",
        "# Opci√≥n 2: Definir una carpeta y nombre espec√≠ficos (descomenta si prefieres esta)\n",
        "carpeta_salida_especifica = \"/content/drive/MyDrive/transcipciones/Transcipciones hechas/Clases sin formato \" # <-------------------------------------------------- ESTA ES LA CARPETA DE SALIDA\n",
        "nombre_archivo_salida = \"Bio 27-06(2).txt\" # <-------------------------------------------------- HAY QUE MODIFICAR ESTE ARCHIVO DE TEXTO, CON ESTE NOMBRE SALDRA, SI NO SE CAMBIA SOBREESCRIBIRA EL ANTERIOR\n",
        "#Aseg√∫rate de que la carpeta exista (o cr√©ala)\n",
        "# os.makedirs(carpeta_salida_especifica, exist_ok=True)\n",
        "ruta_archivo_txt = os.path.join(carpeta_salida_especifica, nombre_archivo_salida)\n",
        "\n",
        "print(f\"El archivo de audio es: {ruta_del_audio}\")\n",
        "print(f\"La transcripci√≥n se guardar√° en: {ruta_archivo_txt}\")\n",
        "\n",
        "# --- PASO 4: Cargar el modelo Whisper ---\n",
        "print(\"Cargando modelo Whisper (medium)...\")\n",
        "try:\n",
        "    model = whisper.load_model(\"medium\")\n",
        "    print(\"Modelo cargado.\")\n",
        "\n",
        "    # --- PASO 5: Verificar que el archivo existe y Transcribir ---\n",
        "    print(f\"Intentando transcribir el archivo...\")\n",
        "\n",
        "    if not os.path.exists(ruta_del_audio):\n",
        "        print(f\"\\n--- ERROR --- El archivo NO se encontr√≥ en: {ruta_del_audio}\")\n",
        "        # ... (resto del mensaje de error) ...\n",
        "    else:\n",
        "        # Transcribir el archivo\n",
        "        result = model.transcribe(ruta_del_audio, language=\"es\", fp16=False)\n",
        "        transcription_text = result[\"text\"] # Guardamos el texto en una variable\n",
        "\n",
        "        # --- PASO 6: Mostrar el texto transcrito ---\n",
        "        print(\"\\n-- TRANSCRIPCI√ìN OBTENIDA --\\n\")\n",
        "        print(transcription_text)\n",
        "\n",
        "        # --- PASO 7: GUARDAR la transcripci√≥n en el archivo .txt ---\n",
        "        try:\n",
        "            print(f\"\\nGuardando transcripci√≥n en {ruta_archivo_txt}...\")\n",
        "            # Abrimos el archivo en modo escritura ('w') con codificaci√≥n UTF-8\n",
        "            with open(ruta_archivo_txt, 'w', encoding='utf-8') as f:\n",
        "                f.write(transcription_text) # Escribimos el texto\n",
        "            print(\"¬°Transcripci√≥n guardada exitosamente!\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\n--- ERROR AL GUARDAR EL ARCHIVO ---\")\n",
        "            print(f\"No se pudo guardar la transcripci√≥n en {ruta_archivo_txt}\")\n",
        "            print(f\"Error: {e}\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"Error: No se pudo importar Whisper. ¬øEjecutaste '!pip install git+https://github.com/openai/whisper.git'?\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n--- Ocurri√≥ un Error Inesperado ---\")\n",
        "    print(e)\n",
        "    print(\"\\nSugerencias:\")\n",
        "    print(\"- Verifica la instalaci√≥n de Whisper.\")\n",
        "    print(\"- Aseg√∫rate de que el archivo de audio no est√© corrupto.\")\n",
        "    print(\"- Revisa si tienes suficiente memoria RAM/GPU (prueba un modelo m√°s peque√±o como 'base' o 'small').\")\n",
        "    print(f\"\\n--- Ocurri√≥ un Error Inesperado ---\")\n",
        "    print(e)\n",
        "    print(\"\\nSugerencias:\")\n",
        "    print(\"- Verifica la instalaci√≥n de Whisper.\")\n",
        "    print(\"- Aseg√∫rate de que el archivo de audio no est√© corrupto.\")\n",
        "    print(\"- Revisa si tienes suficiente memoria RAM/GPU (prueba un modelo m√°s peque√±o como 'base' o 'small').\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7FxKQeMAeNm"
      },
      "source": [
        "# **Esto es para dar formato al texto **, Le pide una solicitud por API a GEMINI Para dar formato, el prompt esta abajo por si hay necesidad de cambiarlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "huTZrQPv5wXD",
        "outputId": "6f36d9ae-9260-42d9-c26f-2d8f9a2d25b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clave API de Google configurada exitosamente desde Secretos.\n",
            "Archivo crudo a leer: /content/drive/MyDrive/transcipciones/Transcipciones hechas/Clases sin formato /Copia de Grupo focal.txt\n",
            "Archivo formateado se guardar√° en: /content/drive/MyDrive/transcipciones/Transcipciones hechas/Clases sin formato /Copia de Grupo focal_formateado.txt\n",
            "--- ERROR LEYENDO ARCHIVO ---\n",
            "El archivo de entrada no existe: /content/drive/MyDrive/transcipciones/Transcipciones hechas/Clases sin formato /Copia de Grupo focal.txt\n",
            "Verifica que la ruta sea correcta y que el archivo exista en Google Drive.\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-561770964.py\", line 56, in <cell line: 0>\n",
            "    raise FileNotFoundError(f\"El archivo de entrada no existe: {ruta_archivo_crudo_txt}\")\n",
            "FileNotFoundError: El archivo de entrada no existe: /content/drive/MyDrive/transcipciones/Transcipciones hechas/Clases sin formato /Copia de Grupo focal.txt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-561770964.py\", line 70, in <cell line: 0>\n",
            "    raise SystemExit(\"No se puede continuar sin leer el archivo de entrada.\")\n",
            "SystemExit: No se puede continuar sin leer el archivo de entrada.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1769, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1701, in getframeinfo\n",
            "    lineno = frame.f_lineno\n",
            "             ^^^^^^^^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'f_lineno'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-561770964.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruta_archivo_crudo_txt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m          \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"El archivo de entrada no existe: {ruta_archivo_crudo_txt}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: El archivo de entrada no existe: /content/drive/MyDrive/transcipciones/Transcipciones hechas/Clases sin formato /Copia de Grupo focal.txt",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-561770964.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Verifica que la ruta sea correcta y que el archivo exista en Google Drive.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No se puede continuar sin leer el archivo de entrada.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: No se puede continuar sin leer el archivo de entrada.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "# --- PASO 1: Instalar la librer√≠a de Google Generative AI ---\n",
        "!pip install google-generativeai -q\n",
        "\n",
        "# --- PASO 2: Importar librer√≠as necesarias ---\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import userdata # Para manejar la API Key de forma segura\n",
        "\n",
        "# --- PASO 3: Configurar tu Clave API de Google ---\n",
        "# ¬°¬°¬°MUY IMPORTANTE!!! Guarda tu clave API como un SECRETO en Colab:\n",
        "# 1. Clic en el icono de llave (üîë) en el panel izquierdo de Colab.\n",
        "# 2. Clic en \"+ Agregar nuevo secreto\".\n",
        "# 3. Nombre: GOOGLE_API_KEY (o el nombre que prefieras, pero s√© consistente)\n",
        "# 4. Valor: Pega tu clave API completa aqu√≠.\n",
        "# 5. Activa el interruptor \"Acceso al notebook\".\n",
        "API_KEY_SECRET_NAME = \"GOOGLE_API_KEY\" # <--------------------------------- SI ESTO NO FUNCIONA AL INTENTAR REPRODUCIR, LO IDEAL ES IR A GEMINI, INICIAR SESION Y SOLICITAR UNA API KEY QUE SE PEGA DONDE ESTA LA LLAVE A LA IZQUIERDA EN EL PANEL\n",
        "# Aseg√∫rate que este nombre coincida con el secreto que creaste\n",
        "\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get(API_KEY_SECRET_NAME)\n",
        "    if not GOOGLE_API_KEY:\n",
        "        raise ValueError(f\"Secreto '{API_KEY_SECRET_NAME}' no encontrado o vac√≠o.\")\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"Clave API de Google configurada exitosamente desde Secretos.\")\n",
        "except Exception as e:\n",
        "    print(f\"--- ERROR CONFIGURANDO API KEY ---\")\n",
        "    print(f\"Error: {e}\")\n",
        "    print(f\"Aseg√∫rate de haber creado un secreto llamado '{API_KEY_SECRET_NAME}' en Colab con tu clave API de Google.\")\n",
        "    # Detener la ejecuci√≥n si no hay clave\n",
        "    raise SystemExit(\"No se puede continuar sin la clave API.\")\n",
        "\n",
        "# --- PASO 4: Definir rutas de los archivos ---\n",
        "# !!! CAMBIA ESTA RUTA al archivo .txt con la transcripci√≥n CRUDA que guardaste ANTES !!!\n",
        "ruta_archivo_crudo_txt = \"/content/drive/MyDrive/transcipciones/Transcipciones hechas/Clases sin formato /Copia de Grupo focal.txt\" # <----------------------------------------------------- ¬°¬°TU ARCHIVO CRUDO!!, ES EL ARCHIVO TXT CON LA ENSALADA DE LETRAS\n",
        "# --- Definir d√≥nde guardar el archivo formateado ---\n",
        "# (Se guardar√° en la misma carpeta que el crudo, con \"_formateado\" a√±adido al nombre)\n",
        "try:\n",
        "    input_path = Path(ruta_archivo_crudo_txt)  # <-------------------------------------- ESTO LE DICE QUE SE GUARDARA EN LA MISMA CARPETA DONDE QUEDO EL CRUDO.\n",
        "    # Crear nombre base, quitando posible extensi√≥n .txt si existe (aunque ya es txt)\n",
        "    nombre_base = input_path.stem\n",
        "    # A√±adir sufijo y extensi√≥n\n",
        "    output_filename = f\"{nombre_base}_formateado.txt\"\n",
        "    # Crear ruta completa de salida\n",
        "    ruta_archivo_formateado_txt = input_path.parent / output_filename\n",
        "    print(f\"Archivo crudo a leer: {ruta_archivo_crudo_txt}\")\n",
        "    print(f\"Archivo formateado se guardar√° en: {ruta_archivo_formateado_txt}\")\n",
        "except Exception as e:\n",
        "     print(f\"Error al definir rutas de archivo: {e}\")\n",
        "     raise SystemExit(\"No se puede continuar sin rutas v√°lidas.\")\n",
        "\n",
        "# --- PASO 5: Leer el contenido del archivo de texto crudo ---\n",
        "texto_crudo = \"\"\n",
        "try:\n",
        "    if not os.path.exists(ruta_archivo_crudo_txt):\n",
        "         raise FileNotFoundError(f\"El archivo de entrada no existe: {ruta_archivo_crudo_txt}\")\n",
        "\n",
        "    with open(ruta_archivo_crudo_txt, 'r', encoding='utf-8') as f:\n",
        "        texto_crudo = f.read()\n",
        "    print(f\"\\nTexto crudo le√≠do exitosamente del archivo. Longitud: {len(texto_crudo)} caracteres.\")\n",
        "    if not texto_crudo.strip():\n",
        "         print(\"ADVERTENCIA: El archivo de texto crudo parece estar vac√≠o.\")\n",
        "         # Podr√≠as decidir detenerte aqu√≠ si est√° vac√≠o\n",
        "         # raise SystemExit(\"El archivo de entrada est√° vac√≠o.\")\n",
        "\n",
        "except FileNotFoundError as fnf_error:\n",
        "    print(f\"--- ERROR LEYENDO ARCHIVO ---\")\n",
        "    print(fnf_error)\n",
        "    print(\"Verifica que la ruta sea correcta y que el archivo exista en Google Drive.\")\n",
        "    raise SystemExit(\"No se puede continuar sin leer el archivo de entrada.\")\n",
        "except Exception as e:\n",
        "    print(f\"--- ERROR LEYENDO ARCHIVO ---\")\n",
        "    print(f\"Ocurri√≥ un error inesperado al leer {ruta_archivo_crudo_txt}: {e}\")\n",
        "    raise SystemExit(\"No se puede continuar sin leer el archivo de entrada.\")\n",
        "\n",
        "# --- PASO 6: Preparar y llamar a la API de Google Gemini ---\n",
        "if texto_crudo.strip(): # Solo proceder si hay texto\n",
        "    print(\"\\nPreparando para formatear con Google Gemini...\")\n",
        "\n",
        "    # Elige el modelo de Gemini (gemini-1.5-flash es r√°pido y econ√≥mico)\n",
        "    # Puedes probar 'gemini-1.5-pro-latest' para potencialmente m√°s calidad\n",
        "    model_name = 'gemini-1.5-pro-latest'\n",
        "    model = genai.GenerativeModel(model_name)\n",
        "\n",
        "    # Define la instrucci√≥n (prompt) para el formateo\n",
        "    prompt_instruccion = f\"\"\"Por favor, toma la siguiente transcripci√≥n de audio y format√©ala para mejorar significativamente su legibilidad. Realiza las siguientes acciones:\n",
        "1.  Divide el texto en p√°rrafos coherentes donde haya cambios de tema, de hablante (si es discernible) o pausas largas impl√≠citas. Usa doble salto de l√≠nea entre p√°rrafos.\n",
        "2.  Corrige y a√±ade la puntuaci√≥n necesaria (comas, puntos, may√∫sculas iniciales, signos de interrogaci√≥n/exclamaci√≥n donde corresponda).\n",
        "3.  Aseg√∫rate de que las frases est√©n bien estructuradas gramaticalmente.\n",
        "4.  No a√±adas contenido, informaci√≥n o res√∫menes que no est√©n en el texto original. Solo formatea el texto existente.\n",
        "5.  Mant√©n el idioma original de la transcripci√≥n.\n",
        "\n",
        "Aqu√≠ est√° la transcripci√≥n cruda:\n",
        "\n",
        "{texto_crudo}\"\"\"\n",
        "\n",
        "    try:\n",
        "        print(f\"Enviando solicitud al modelo {model_name}...\")\n",
        "        # Llama a la API\n",
        "        response = model.generate_content(prompt_instruccion)\n",
        "\n",
        "        # Extrae el texto formateado de la respuesta\n",
        "        formatted_text_gemini = response.text\n",
        "\n",
        "        print(\"\\n--- TEXTO FORMATEADO POR GEMINI ---\")\n",
        "        print(formatted_text_gemini)\n",
        "\n",
        "        # --- PASO 7: Guardar el texto formateado en un nuevo archivo ---\n",
        "        try:\n",
        "            print(f\"\\nGuardando texto formateado en: {ruta_archivo_formateado_txt}...\")\n",
        "            with open(ruta_archivo_formateado_txt, 'w', encoding='utf-8') as f:\n",
        "                f.write(formatted_text_gemini)\n",
        "            print(\"¬°Texto formateado guardado exitosamente!\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\n--- ERROR AL GUARDAR EL ARCHIVO FORMATEADO ---\")\n",
        "            print(f\"No se pudo guardar la transcripci√≥n formateada en {ruta_archivo_formateado_txt}\")\n",
        "            print(f\"Error: {e}\")\n",
        "            print(\"Verifica los permisos de escritura en Google Drive.\")\n",
        "\n",
        "    # Manejo espec√≠fico de errores de la API de Google\n",
        "    except Exception as e:\n",
        "        print(f\"\\n--- ERROR AL LLAMAR A LA API DE GEMINI ---\")\n",
        "        print(f\"Ocurri√≥ un error: {e}\")\n",
        "        print(\"Verifica tu conexi√≥n a internet, tu clave API y los l√≠mites de uso de Google Cloud.\")\n",
        "\n",
        "else:\n",
        "     print(\"\\nEl texto crudo est√° vac√≠o, no se realizar√° el formateo.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3gvnzo5AUzo"
      },
      "source": [
        "\n",
        "# **Esto es para grabar desde el pc ** FASE BETA, DEBE EXISTIR UNA SOLICITUD DE MICROFONO ANTES SI NO GENERA CONFLICTO AL CORRER EL CODIGO, aun no soluciono desconecccion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- INSTALAR DEPENDENCIAS SOLO UNA VEZ ---\n",
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "!pip install ffmpeg-python -q\n",
        "!pip install -U ffmpeg-python\n"
      ],
      "metadata": {
        "id": "X7wPNRv-a8RV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850e3219-3015-4955-a5a3-15b5b2bd4d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "I4hvG7h-pzoU",
        "outputId": "3f301b91-61d7-40e8-e58e-92f4f956a955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Cargando modelo Whisper (medium)...\n",
            "‚úÖ Modelo cargado.\n",
            "üéß Iniciando grabaci√≥n...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "(async () => {\n",
              "  let base64data = 0;\n",
              "  let recorder, gumStream, reader;\n",
              "  let recording = false;\n",
              "\n",
              "  const container = document.createElement(\"div\");\n",
              "  const button = document.createElement(\"button\");\n",
              "  const estado = document.createElement(\"p\");\n",
              "\n",
              "  button.textContent = \"üéôÔ∏è Presiona para grabar\";\n",
              "  estado.textContent = \"Esperando interacci√≥n del usuario...\";\n",
              "  container.appendChild(button);\n",
              "  container.appendChild(estado);\n",
              "  document.body.appendChild(container);\n",
              "\n",
              "  button.onclick = async () => {\n",
              "    if (!recording) {\n",
              "      try {\n",
              "        estado.textContent = \"Solicitando acceso al micr√≥fono...\";\n",
              "        gumStream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
              "        estado.textContent = \"Grabando... vuelve a presionar para detener.\";\n",
              "        button.textContent = \"‚èπÔ∏è Detener grabaci√≥n\";\n",
              "\n",
              "        const options = { mimeType: 'audio/webm;codecs=opus' };\n",
              "        try {\n",
              "          recorder = new MediaRecorder(gumStream, options);\n",
              "        } catch (e) {\n",
              "          console.warn(\"mimeType no soportado, usando por defecto\", e);\n",
              "          recorder = new MediaRecorder(gumStream);\n",
              "        }\n",
              "\n",
              "        recorder.ondataavailable = (e) => {\n",
              "          reader = new FileReader();\n",
              "          reader.readAsDataURL(e.data);\n",
              "          reader.onloadend = () => {\n",
              "            base64data = reader.result;\n",
              "          };\n",
              "        };\n",
              "\n",
              "        recorder.start();\n",
              "        recording = true;\n",
              "\n",
              "      } catch (err) {\n",
              "        console.error(\"Error al acceder al micr√≥fono:\", err);\n",
              "        estado.textContent = \"‚ùå Error: \" + err.message;\n",
              "        button.disabled = true;\n",
              "      }\n",
              "    } else {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      estado.textContent = \"Procesando grabaci√≥n...\";\n",
              "      button.textContent = \"‚úÖ Grabaci√≥n completa\";\n",
              "      button.disabled = true;\n",
              "      recording = false;\n",
              "    }\n",
              "  };\n",
              "\n",
              "  Object.defineProperty(window, 'base64data', {\n",
              "    get: function() {\n",
              "      return base64data;\n",
              "    }\n",
              "  });\n",
              "})();\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé§ Presiona el bot√≥n para grabar y vuelve a presionar para detener...\n",
            "‚è∞ Tiempo de espera agotado (60s).\n",
            "üö´ Grabaci√≥n fallida o cancelada.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- IMPORTACIONES NECESARIAS ---\n",
        "import numpy as np\n",
        "import whisper\n",
        "import time\n",
        "import ffmpeg\n",
        "from base64 import b64decode\n",
        "from IPython.display import Javascript, display, Audio\n",
        "from google.colab.output import eval_js\n",
        "from scipy.io.wavfile import write as write_wav\n",
        "import os\n",
        "\n",
        "# --- BLOQUE JAVASCRIPT FIJO PARA GOOGLE COLAB ---\n",
        "AUDIO_HTML = \"\"\"\n",
        "(async () => {\n",
        "  let base64data = 0;\n",
        "  let recorder, gumStream, reader;\n",
        "  let recording = false;\n",
        "\n",
        "  const container = document.createElement(\"div\");\n",
        "  const button = document.createElement(\"button\");\n",
        "  const estado = document.createElement(\"p\");\n",
        "\n",
        "  button.textContent = \"üéôÔ∏è Presiona para grabar\";\n",
        "  estado.textContent = \"Esperando interacci√≥n del usuario...\";\n",
        "  container.appendChild(button);\n",
        "  container.appendChild(estado);\n",
        "  document.body.appendChild(container);\n",
        "\n",
        "  button.onclick = async () => {\n",
        "    if (!recording) {\n",
        "      try {\n",
        "        estado.textContent = \"Solicitando acceso al micr√≥fono...\";\n",
        "        gumStream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
        "        estado.textContent = \"Grabando... vuelve a presionar para detener.\";\n",
        "        button.textContent = \"‚èπÔ∏è Detener grabaci√≥n\";\n",
        "\n",
        "        const options = { mimeType: 'audio/webm;codecs=opus' };\n",
        "        try {\n",
        "          recorder = new MediaRecorder(gumStream, options);\n",
        "        } catch (e) {\n",
        "          console.warn(\"mimeType no soportado, usando por defecto\", e);\n",
        "          recorder = new MediaRecorder(gumStream);\n",
        "        }\n",
        "\n",
        "        recorder.ondataavailable = (e) => {\n",
        "          reader = new FileReader();\n",
        "          reader.readAsDataURL(e.data);\n",
        "          reader.onloadend = () => {\n",
        "            base64data = reader.result;\n",
        "          };\n",
        "        };\n",
        "\n",
        "        recorder.start();\n",
        "        recording = true;\n",
        "\n",
        "      } catch (err) {\n",
        "        console.error(\"Error al acceder al micr√≥fono:\", err);\n",
        "        estado.textContent = \"‚ùå Error: \" + err.message;\n",
        "        button.disabled = true;\n",
        "      }\n",
        "    } else {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      estado.textContent = \"Procesando grabaci√≥n...\";\n",
        "      button.textContent = \"‚úÖ Grabaci√≥n completa\";\n",
        "      button.disabled = true;\n",
        "      recording = false;\n",
        "    }\n",
        "  };\n",
        "\n",
        "  Object.defineProperty(window, 'base64data', {\n",
        "    get: function() {\n",
        "      return base64data;\n",
        "    }\n",
        "  });\n",
        "})();\n",
        "\"\"\"\n",
        "\n",
        "# --- FUNCI√ìN PARA GRABAR AUDIO ---\n",
        "def get_audio(sample_rate=16000, timeout_sec=60):\n",
        "  try:\n",
        "    display(Javascript(AUDIO_HTML))\n",
        "    print(\"üé§ Presiona el bot√≥n para grabar y vuelve a presionar para detener...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    data = 0\n",
        "    while True:\n",
        "        try:\n",
        "            data = eval_js(\"base64data\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        if data != 0:\n",
        "            print(\"‚úîÔ∏è Audio recibido desde JavaScript.\")\n",
        "            break\n",
        "\n",
        "        if time.time() - start_time > timeout_sec:\n",
        "            print(f\"‚è∞ Tiempo de espera agotado ({timeout_sec}s).\")\n",
        "            return None, None\n",
        "\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    if not data or data == '0':\n",
        "        print(\"‚ö†Ô∏è No se recibi√≥ audio.\")\n",
        "        return None, None\n",
        "\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "\n",
        "    process = (\n",
        "        ffmpeg\n",
        "        .input('pipe:0')\n",
        "        .output('pipe:1', format='s16le', acodec='pcm_s16le', ac=1, ar=str(sample_rate))\n",
        "        .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "    )\n",
        "    output, err = process.communicate(input=binary)\n",
        "\n",
        "    if process.poll() != 0 or not output:\n",
        "        print(\"‚ùå Error en conversi√≥n con ffmpeg.\")\n",
        "        return None, None\n",
        "\n",
        "    audio_np = np.frombuffer(output, dtype=np.int16).astype(np.float32) / 32768.0\n",
        "    return audio_np, sample_rate\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"‚ùå Error inesperado: {e}\")\n",
        "    return None, None\n",
        "\n",
        "# --- CARGA DEL MODELO WHISPER ---\n",
        "print(\"üì¶ Cargando modelo Whisper (medium)...\")\n",
        "model = whisper.load_model(\"medium\")\n",
        "print(\"‚úÖ Modelo cargado.\")\n",
        "\n",
        "# --- GRABAR AUDIO ---\n",
        "print(\"üéß Iniciando grabaci√≥n...\")\n",
        "audio, sr = get_audio(timeout_sec=60)\n",
        "\n",
        "# --- PROCESAR Y GUARDAR ---\n",
        "if audio is not None and sr is not None:\n",
        "    # Ruta en Google Drive donde guardar√°s el archivo\n",
        "    ruta_drive = \"/content/drive/MyDrive/audio_colab/\"\n",
        "    os.makedirs(ruta_drive, exist_ok=True)\n",
        "\n",
        "    archivo_wav = os.path.join(ruta_drive, \"grabacion.wav\")\n",
        "    audio_int16 = np.int16(audio * 32767)\n",
        "    write_wav(archivo_wav, sr, audio_int16)\n",
        "    print(f\"üíæ Archivo de audio guardado en: {archivo_wav}\")\n",
        "\n",
        "    # TRANSCRIBIR\n",
        "    print(\"üß† Transcribiendo audio con Whisper...\")\n",
        "    result = model.transcribe(archivo_wav, language=\"es\", task=\"transcribe\", fp16=False)\n",
        "\n",
        "    print(\"\\nüìÑ TRANSCRIPCI√ìN:\\n\")\n",
        "    print(result[\"text\"])\n",
        "\n",
        "    # GUARDAR TRANSCRIPCI√ìN COMO ARCHIVO TXT\n",
        "    archivo_txt = os.path.join(ruta_drive, \"transcripcion.txt\")\n",
        "    with open(archivo_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(result[\"text\"])\n",
        "    print(f\"\\nüìù Transcripci√≥n guardada como archivo: {archivo_txt}\")\n",
        "\n",
        "else:\n",
        "    print(\"üö´ Grabaci√≥n fallida o cancelada.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PASO 1: Instalaci√≥n ---\n",
        "!pip install -q -U torch transformers bitsandbytes accelerate\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import textwrap\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# --- PASO 2: Cargar Phi-3.5 Mini con 128k de contexto ---\n",
        "print(\"Cargando Phi-3.5 Mini (128k Context)...\")\n",
        "model_id = \"microsoft/Phi-3.5-mini-instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    # No necesitamos load_in_4bit obligatoriamente porque el modelo es peque√±o,\n",
        "    # pero ayuda a dejar M√ÅS espacio para tu texto largo.\n",
        "    load_in_4bit=True\n",
        ")\n",
        "\n",
        "# --- PASO 3: Rutas (Igual que siempre) ---\n",
        "ruta_archivo_crudo_txt = \"/content/drive/MyDrive/transcipciones/Transcipciones hechas/Clases sin formato /Copia de Grupo focal.txt\"\n",
        "# Ajusta la ruta si es necesario\n",
        "\n",
        "# --- PASO 4: Funci√≥n de Formato ---\n",
        "def formatear_con_phi(texto_input):\n",
        "    prompt = f\"\"\"<|system|>\n",
        "Eres un editor experto. Tu tarea es formatear la siguiente transcripci√≥n.\n",
        "REGLAS:\n",
        "1. A√±ade puntuaci√≥n, corrige gram√°tica y estructura en p√°rrafos.\n",
        "2. NO RESUMAS. Mant√©n todo el contenido.\n",
        "3. Devuelve solo el texto formateado.\n",
        "<|end|>\n",
        "<|user|>\n",
        "Texto:\n",
        "{texto_input}\n",
        "<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Phi soporta mucho contexto, as√≠ que podemos generar bastante salida\n",
        "    outputs = model.generate(\n",
        "        **input_ids,\n",
        "        max_new_tokens=4000, # Generar hasta 4000 nuevos tokens de salida\n",
        "        temperature=0.1,\n",
        "        do_sample=True\n",
        "    )\n",
        "\n",
        "    # Decodificar solo la parte nueva\n",
        "    generated_text = tokenizer.decode(outputs[0][input_ids.input_ids.shape[1]:], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "# --- PASO 5: Procesamiento con CHUNKS GRANDES ---\n",
        "# Con Phi-3.5, podemos procesar bloques mucho m√°s grandes que con otros modelos.\n",
        "# Un chunk de 12,000 caracteres son unas 5-7 p√°ginas de golpe.\n",
        "TAMANO_CHUNK = 12000\n",
        "\n",
        "if os.path.exists(ruta_archivo_crudo_txt):\n",
        "    with open(ruta_archivo_crudo_txt, 'r', encoding='utf-8') as f:\n",
        "        texto_crudo = f.read()\n",
        "\n",
        "    trozos = textwrap.wrap(texto_crudo, TAMANO_CHUNK, break_long_words=False, replace_whitespace=False)\n",
        "    print(f\"Procesando texto en {len(trozos)} partes grandes...\")\n",
        "\n",
        "    texto_final = []\n",
        "    for i, trozo in enumerate(trozos):\n",
        "        print(f\"Formateando parte {i+1}/{len(trozos)}...\")\n",
        "        try:\n",
        "            res = formatear_con_phi(trozo)\n",
        "            texto_final.append(res)\n",
        "        except Exception as e:\n",
        "            print(f\"Error en parte {i+1}: {e}\")\n",
        "            # Si falla por memoria, intentamos guardar lo que llevamos\n",
        "            break\n",
        "\n",
        "    # Guardar\n",
        "    ruta_salida = Path(ruta_archivo_crudo_txt).parent / f\"{Path(ruta_archivo_crudo_txt).stem}_phi3_formateado.txt\"\n",
        "    with open(ruta_salida, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"\\n\".join(texto_final))\n",
        "    print(f\"Guardado en: {ruta_salida}\")\n",
        "else:\n",
        "    print(\"Archivo no encontrado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIYEZ58ZeiJi",
        "outputId": "bd2cc93a-75d8-4314-b305-f670ce5add41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.9.1 which is incompatible.\n",
            "torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "u3gvnzo5AUzo"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}